import requests

from bs4 import BeautifulSoup

url = requests.get("https://www.yelp.com/biz/tesla-san-francisco?osq=Tesla+Dealership")

url.status_code

url.text

soup = BeautifulSoup(url.text, "html.parser")

divs = soup.findAll(class_="comment__09f24__gu0rG css-qgunke")
print(divs)

reviews = []
for div in divs:
    reviews.append(div.find('span').text)

reviews[0]

# Analysing the data

import pandas as pd
import numpy as np

df = pd.DataFrame(np.array(reviews), columns=["review"])

len(df['review'])

df["word_count"] = df["review"].apply(lambda x: len(x.split()))

df['char_count']=df['review'].apply(lambda x: len(x))

def avg_word(review):
  words = review.split()
  return (sum(len(word) for word in words) / len(words))

# Calculate average words
df['avg_word'] = df['review'].apply(lambda x: avg_word(x))

df.head()

!pip3 install nltk

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Import stopwords
from nltk.corpus import stopwords 

stop_words = stopwords.words('english')
df['stopword_count'] = df['review'].apply(lambda x: len([x for x in x.split() if x in stop_words]))

df.describe()

df.head()

df["stopword_rate"] = df["stopword_count"] /df["word_count"]

df.head()

df.sort_values(by="stopword_rate")

# Data Cleaning

df["lowercase"] = df["review"].apply(lambda x: " ".join(word.lower() for word in x.split()))

df["Punctuation"] = df["lowercase"].str.replace('[^\w\s]',"")

df["Stopwords"] = df["Punctuation"].apply(lambda x:" ".join(word for word in x.split() if word not in stop_words))

df.head()

pd.Series(" ".join(df['Stopwords']).split()).value_counts()[:30]

other_stop_words=["us", "get", "would","go", "ap", "melissa", "kevin", "bridget", "say" ]

len(other_stop_words)

df["Clean Review"] = df["Stopwords"].apply(lambda x: " ".join(word for word in x.split() if word not in other_stop_words))

df.head()

# Lemmatize Text

!pip install textblob

#Import textblob
from textblob import Word

df["lemmatized"] = df["Clean Review"].apply(lambda x: " ".join(Word(word).lemmatize() for word in x.split()))

df.head()

# Sentiment Analysis

from textblob import TextBlob

df["polarity"] = df["lemmatized"].apply(lambda x: TextBlob(x).sentiment[0])

df["subjectivity"] = df["lemmatized"].apply(lambda x: TextBlob(x).sentiment[1])

df.head()

df.drop(["lowercase", "Punctuation", "Stopwords","Clean Review", "lemmatized"], axis=1, inplace=True)

df.sort_values(by="polarity")

